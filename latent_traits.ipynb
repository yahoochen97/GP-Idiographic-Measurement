{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gpytorch\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "\n",
    "from scipy.stats import norm\n",
    "torch.manual_seed(8927)\n",
    "np.random.seed(8927)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.mlls import VariationalELBO\n",
    "from gpytorch.priors import NormalPrior, MultivariateNormalPrior\n",
    "from gpytorch.likelihoods import BernoulliLikelihood\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import LinearKernel, RBFKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "from utilities.util import MyDirichletClassificationLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(\"./data/item_long_unimp.csv\")\n",
    "\n",
    "# SID: the subject ID\n",
    "# all_beeps: the assessment wave\n",
    "# Trait: one of the Big Five\n",
    "# Facet: one of the facets hypothesized to be under one of the Big Five traits (3 of each big 5)\n",
    "# Item: the item name (4 per facet)\n",
    "# Value: the rating \n",
    "\n",
    "data = data[(data.all_beeps<=2000)]\n",
    "SIDs = data.SID.unique()\n",
    "SIDs.sort()\n",
    "Items = data.Item.unique()\n",
    "Items.sort()\n",
    "Beeps = data.all_beeps.unique()\n",
    "Beeps.sort()\n",
    "TRAITS = data.Trait.unique()\n",
    "C = max(data.value.unique())\n",
    "\n",
    "n = len(SIDs)\n",
    "m = len(Items)\n",
    "horizon = len(Beeps)\n",
    "Q = len(TRAITS)\n",
    "\n",
    "# x: [i,j,h]\n",
    "train_x = torch.zeros((data.shape[0],3))\n",
    "train_y = torch.zeros((data.shape[0],))\n",
    "\n",
    "iter = 0\n",
    "for _, row in data.iterrows():\n",
    "    i = np.where(row[\"SID\"]==SIDs)[0][0]\n",
    "    j = np.where(row[\"Item\"]==Items)[0][0]\n",
    "    h = np.where(row[\"all_beeps\"]==Beeps)[0][0]\n",
    "    train_x[iter, 0] = i\n",
    "    train_x[iter, 1] = j\n",
    "    train_x[iter, 2] = h\n",
    "    train_y[iter] = row[\"value\"] - 1\n",
    "    iter += 1\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_mask = np.zeros((data.shape[0],))\n",
    "train_mask[np.random.choice(data.shape[0], int(data.shape[0]*train_ratio),replace=False)] = 1\n",
    "test_x = train_x[train_mask==0]\n",
    "test_y = train_y[train_mask==0]\n",
    "train_x = train_x[train_mask==1]\n",
    "train_y = train_y[train_mask==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dirichlet-based Gaussian Processes for Large-Scale Calibrated Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.kernels import RBFKernel, IndexKernel\n",
    "from utilities.util import MyDirichletClassificationLikelihood, OrdinalLikelihood\n",
    "from gpytorch.means import Mean\n",
    "\n",
    "class ConstantVectorMean(Mean):\n",
    "    def __init__(self, size, prior=None, batch_shape=torch.Size(), **kwargs):\n",
    "        super().__init__()\n",
    "        self.batch_shape = batch_shape\n",
    "        self.register_parameter(name=\"constantvector\",\\\n",
    "                 parameter=torch.nn.Parameter(torch.zeros(*batch_shape, *size)))\n",
    "        if prior is not None:\n",
    "            self.register_prior(\"constantvector_prior\", prior, \"constantvector\")\n",
    "\n",
    "    def forward(self, input):\n",
    "        results = torch.zeros((input.shape[0],))\n",
    "        for i in range(input.shape[0]):\n",
    "            results[i] = self.constantvector[input[i,0].int(),input[i,1].int()]\n",
    "        return results\n",
    "\n",
    "class OrdinalLMC(ApproximateGP):\n",
    "    def __init__(self, inducing_points, n, m, C):\n",
    "        self.C = C # cardinality of responses\n",
    "\n",
    "        # Sparse Variational Formulation\n",
    "        q_u = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        q_f = VariationalStrategy(self, inducing_points, q_u, \\\n",
    "                                  learn_inducing_locations=True)\n",
    "        super().__init__(q_f)\n",
    "\n",
    "        self.mean_module = ConstantVectorMean(size=torch.Size((n,m)))\n",
    "        self.covar_module = RBFKernel(active_dims=[0]) * \\\n",
    "                RBFKernel(active_dims=[2])\n",
    "        self.task_covar_module = IndexKernel(num_tasks=m, rank=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x[:,:2])\n",
    "        covar_x = self.covar_module(x) * self.task_covar_module(x[:,1])\n",
    "        dist = MultivariateNormal(mean_x, covar_x)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.constraints import Positive\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gpytorch.means import Mean\n",
    "from gpytorch.module import Module\n",
    "from gpytorch.mlls import KLGaussianAddedLossTerm\n",
    "from torch.distributions import MultivariateNormal\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "\n",
    "from gpytorch.distributions import base_distributions\n",
    "from gpytorch.functions import log_normal_cdf\n",
    "from gpytorch.likelihoods.likelihood import _OneDimensionalLikelihood\n",
    "\n",
    "\n",
    "class OrdinalLikelihood(_OneDimensionalLikelihood):\n",
    "    r\"\"\"\n",
    "    Implements the Ordinal likelihood used for GP classification, using\n",
    "    logit regression (i.e., the latent function is warped to be in [0,1]\n",
    "    using the standard Normal CDF :math:`\\Phi(x)`).\n",
    "    .. math::\n",
    "        \\begin{equation*}\n",
    "            p(Y=c|f)=\\Phi(b_c-f)-\\Phi(b_{c-1}-f)\n",
    "        \\end{equation*}\n",
    "    \"\"\"\n",
    "    has_analytic_marginal: bool = True\n",
    "\n",
    "    def __init__(self, thresholds, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.C = thresholds.shape[0] - 1\n",
    "        thresholds, _ = torch.sort(thresholds)\n",
    "        if self.C>2:\n",
    "            self.register_parameter(\"b1\", parameter=torch.nn.Parameter(\\\n",
    "                torch.Tensor(thresholds[1])))\n",
    "        if self.C>3:\n",
    "            self.register_parameter(\"deltas\", parameter=torch.nn.Parameter(\\\n",
    "                self._threshold_to_delta(thresholds)))\n",
    "            self.register_constraint(\"deltas\", Positive())\n",
    "        \n",
    "    def _threshold_to_delta(self, thresholds):\n",
    "        C = self.C\n",
    "        deltas = torch.zeros((C-2,))\n",
    "        deltas[0] = thresholds[1]\n",
    "        for c in range(2,C):\n",
    "            deltas[c-2] = thresholds[c] - thresholds[c-1]\n",
    "        return deltas\n",
    "    \n",
    "    def _delta_to_threshold(self, b1, deltas):\n",
    "        C = self.C\n",
    "        thresholds = torch.zeros((C+1,))\n",
    "        thresholds[0] = torch.tensor([float('-inf')])\n",
    "        thresholds[C] = torch.tensor([float('inf')])\n",
    "        thresholds[1] = b1\n",
    "        for c in range(2,C):\n",
    "            thresholds[c] = thresholds[c-1] + deltas[c-2]\n",
    "        return thresholds\n",
    "    \n",
    "    def _get_thresholds(self):\n",
    "        thresholds = torch.zeros(self.C+1,)\n",
    "        thresholds[0] = float(\"-inf\")\n",
    "        thresholds[self.C] = float(\"inf\")\n",
    "        if self.C>2:\n",
    "            thresholds[1] = self.b1.data\n",
    "        if self.C>3:\n",
    "            thresholds[2:self.C] = self.delta.data\n",
    "        return thresholds\n",
    "\n",
    "    def forward(self, function_samples, **kwargs):\n",
    "        thresholds = self._get_thresholds()\n",
    "        link2 = thresholds[1:] - function_samples\n",
    "        link1 = thresholds[:-1] - function_samples\n",
    "        output_probs = base_distributions.Normal(0, 1).cdf(link2) \\\n",
    "                    -base_distributions.Normal(0, 1).cdf(link1)\n",
    "        return base_distributions.Categorical(probs=output_probs)\n",
    "\n",
    "    def log_marginal(self, observations, function_dist, *args, **kwargs):\n",
    "        marginal = self.marginal(function_dist, *args, **kwargs)\n",
    "        return marginal.log_prob(observations)\n",
    "    \n",
    "    def marginal(self, function_dist, **kwargs):\n",
    "        mean = function_dist.mean\n",
    "        var = function_dist.variance\n",
    "        thresholds = self._get_thresholds()\n",
    "        link2 = (thresholds[1:].unsqueeze(1).unsqueeze(2).repeat(torch.Size([1,*mean.shape]))\\\n",
    "                  - mean).div(torch.sqrt(1+var))\n",
    "        link1 = (thresholds[:-1].unsqueeze(1).unsqueeze(2).repeat(torch.Size([1,*mean.shape]))\\\n",
    "                  - mean).div(torch.sqrt(1+var))\n",
    "        output_probs = base_distributions.Normal(0, 1).cdf(link2) \\\n",
    "                        - base_distributions.Normal(0, 1).cdf(link1)\n",
    "        return base_distributions.Categorical(probs=output_probs)\n",
    "    \n",
    "    def expected_log_prob(self, observations, function_dist, *params, **kwargs):\n",
    "        # Custom function here so we can use log_normal_cdf rather than Normal.cdf\n",
    "        # This is going to be less prone to overflow errors\n",
    "        thresholds = self._get_thresholds()\n",
    "        log_prob_lambda = lambda function_samples: log_normal_cdf((thresholds[observations].unsqueeze(1).unsqueeze(2).repeat(torch.Size([1,*mean.shape]))\\\n",
    "                  - function_dist.mean).div(torch.sqrt(1+function_dist.variance))) \\\n",
    "                  - log_normal_cdf((thresholds[observations-1].unsqueeze(1).unsqueeze(2).repeat(torch.Size([1,*mean.shape]))\\\n",
    "                  - function_dist.mean).div(torch.sqrt(1+function_dist.variance)))\n",
    "        log_prob = self.quadrature(log_prob_lambda, function_dist)\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Invalid expand arguments (-1, -1). Currently, repeat only works to create repeated batches of a 2D LazyTensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f47a414024ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# _, transformed_target_batch = likelihood._prepare_targets(y_batch.long(),\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#                          C,alpha_epsilon=likelihood.alpha_epsilon)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/models/approximate_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, prior, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariational_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdated_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/variational/_variational_strategy.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0minducing_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariational_dist_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0mvariational_inducing_covar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariational_dist_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_covariance_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             )\n\u001b[1;32m    309\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariational_dist_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Compute full prior distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mfull_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minducing_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mfull_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_covariance_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-762040837be3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmean_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mcovar_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovar_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_covar_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovar_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    134\u001b[0m                                  \"with optional leading batch dimensions\")\n\u001b[1;32m    135\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprecision_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(self, *sizes)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             raise RuntimeError(\n\u001b[1;32m   1122\u001b[0m                 \u001b[0;34m\"Invalid expand arguments {}. Currently, repeat only works to create repeated \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                 \u001b[0;34m\"batches of a 2D LazyTensor.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m             )\n\u001b[1;32m   1125\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Invalid expand arguments (-1, -1). Currently, repeat only works to create repeated batches of a 2D LazyTensor."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "load_batch_size = 1024\n",
    "train_loader = DataLoader(train_dataset, batch_size=load_batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=load_batch_size, shuffle=False)\n",
    "\n",
    "# initialize likelihood and model\n",
    "num_inducing = 500\n",
    "inducing_points = train_x[np.random.choice(train_x.size(0),num_inducing,replace=False),:]\n",
    "# likelihood = MyDirichletClassificationLikelihood(train_y.long(), C, learn_additional_noise=True)\n",
    "likelihood = OrdinalLikelihood(thresholds=torch.tensor([float('-inf'),\\\n",
    "                                    -2.,-1.,1.,2.,float('inf')]))\n",
    "\n",
    "model = OrdinalLMC(inducing_points,n,m,C)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "model.covar_module.kernels[0].raw_lengthscale.requires_grad = False\n",
    "model.covar_module.kernels[0].lengthscale = 0.1\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.05)\n",
    "\n",
    "# Our loss object. We're using the VariationalELBO\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for j, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)\n",
    "        # _, transformed_target_batch = likelihood._prepare_targets(y_batch.long(),\\\n",
    "        #                          C,alpha_epsilon=likelihood.alpha_epsilon)\n",
    "        loss = -mll(output, y_batch).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j % 50:\n",
    "            print('Epoch %d Iter %d - Loss: %.3f' % (i + 1, j+1, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "means = torch.zeros((C,1))\n",
    "true_ys = torch.tensor([0])\n",
    "with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        test_dist = model(x_batch)\n",
    "        pred_samples = test_dist.sample(torch.Size((256,))).exp()\n",
    "        probabilities = (pred_samples / pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "        means = torch.cat([means, probabilities],dim=1)\n",
    "        true_ys = torch.cat([true_ys, y_batch])\n",
    "means = means[:,1:]\n",
    "true_ys = true_ys[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.63159658],\n",
       "       [0.63159658, 1.        ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(true_ys, means.argmax(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6110)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(true_ys==means.argmax(dim=0)) / true_ys.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8719)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(true_ys-means.argmax(dim=0))<=1) / true_ys.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "means = torch.zeros((C,1))\n",
    "true_ys = torch.tensor([0])\n",
    "with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        test_dist = model(x_batch)\n",
    "        pred_samples = test_dist.sample(torch.Size((256,))).exp()\n",
    "        probabilities = (pred_samples / pred_samples.sum(-2, keepdim=True)).mean(0)\n",
    "        means = torch.cat([means, probabilities],dim=1)\n",
    "        true_ys = torch.cat([true_ys, y_batch])\n",
    "means = means[:,1:]\n",
    "true_ys = true_ys[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.53409676],\n",
       "       [0.53409676, 1.        ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(true_ys, means.argmax(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5101)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(true_ys==means.argmax(dim=0)) / true_ys.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8357)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(true_ys-means.argmax(dim=0))<=1) / true_ys.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap((model.task_covar_module.covar_matrix.evaluate()).detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
